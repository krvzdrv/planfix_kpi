import psycopg2
import psycopg2.extras
import requests
from datetime import datetime, date, timedelta
import os
import logging
from dotenv import load_dotenv
import sys
from functools import lru_cache
import hashlib
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from core.config import MANAGERS_KPI
from core.kpi_utils import math_round

# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)

PG_HOST = os.environ.get('SUPABASE_HOST')
PG_DB = os.environ.get('SUPABASE_DB')
PG_USER = os.environ.get('SUPABASE_USER')
PG_PASSWORD = os.environ.get('SUPABASE_PASSWORD')
PG_PORT = os.environ.get('SUPABASE_PORT')
TELEGRAM_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
CHAT_ID = os.environ.get('TELEGRAM_CHAT_ID')

HISTORY_TABLE_NAME = "report_clients_status_history"
logger = logging.getLogger(__name__)

# –°—Ç–∞—Ç—É—Å—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏ –∏—Ö –ø–æ—Ä—è–¥–æ–∫ –≤ –æ—Ç—á—ë—Ç–µ
CLIENT_STATUSES = ['NWI', 'WTR', 'PSK', 'PIZ', 'STL', 'NAK', 'REZ', 'BRK', 'ARC']

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞—Ç—É—Å–æ–≤, —á—å—è –ª–æ–≥–∏–∫–∞ –ù–ï –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–∞—Ç (–∫—Ä–æ–º–µ STL)
STATUS_MAPPING = {
    'Nowi': 'NWI',
    'W trakcie': 'WTR',
    'Perspektywiczni': 'PSK',
    'Pierwsze zam√≥wienie': 'PIZ',
    'Stali klienci': 'STL',
    'Rezygnacja': 'REZ',
    'Brak kontaktu': 'BRK',
    'Archiwum': 'ARC'
}

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ —Å –∏—Ö –ø–æ–ª–µ–º –¥–∞—Ç—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ü–†–ò–¢–û–ö–ê
STATUS_INFLOW_DATE_COLS = {
    'NWI': 'data_dodania_do_nowi',
    'WTR': 'data_dodania_do_w_trakcie',
    'PSK': 'data_dodania_do_perspektywiczni',
    'PIZ': 'data_pierwszego_zamowienia',
    'REZ': 'data_dodania_do_rezygnacja',
    'BRK': 'data_dodania_do_brak_kontaktu',
    'ARC': 'data_dodania_do_archiwum',
}

def _execute_query(conn, query: str, params: tuple = (), description: str = "") -> list:
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è."""
    try:
        with conn.cursor() as cur:
            cur.execute(query, params)
            rows = cur.fetchall()
            return rows
    except psycopg2.Error as e:
        logger.error(f"Database error during query for {description}: {e}")
        raise

def create_history_table_if_not_exists(conn):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –¢–û–õ–¨–ö–û –¥–ª—è STL –∏ NAK."""
    query = f"""
    CREATE TABLE IF NOT EXISTS {HISTORY_TABLE_NAME} (
        report_date DATE NOT NULL,
        manager TEXT NOT NULL,
        status TEXT NOT NULL,
        count INTEGER NOT NULL,
        PRIMARY KEY (report_date, manager, status)
    );
    """
    try:
        with conn.cursor() as cur:
            logger.info(f"Checking/Creating history table for STL/NAK: {HISTORY_TABLE_NAME}...")
            cur.execute(query)
            conn.commit()
            logger.info(f"Table {HISTORY_TABLE_NAME} is ready.")
    except psycopg2.Error as e:
        logger.error(f"Error creating history table: {e}")
        conn.rollback()
        raise

def save_statuses_to_history(conn, report_date: date, manager: str, statuses: dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–Ω–µ–≤–Ω–æ–π —Å—Ä–µ–∑ —Å—Ç–∞—Ç—É—Å–æ–≤ STL –∏ NAK –≤ —Ç–∞–±–ª–∏—Ü—É –∏—Å—Ç–æ—Ä–∏–∏."""
    query = f"""
    INSERT INTO {HISTORY_TABLE_NAME} (report_date, manager, status, count)
    VALUES (%s, %s, %s, %s)
    ON CONFLICT (report_date, manager, status) DO UPDATE SET
        count = EXCLUDED.count;
    """
    records = [(report_date, manager, status, count) for status, count in statuses.items() if status in ['STL', 'NAK']]
    if not records:
        return
    try:
        with conn.cursor() as cur:
            psycopg2.extras.execute_batch(cur, query, records)
            conn.commit()
            logger.info(f"Saved {len(records)} STL/NAK records to history for {manager} on {report_date}.")
    except psycopg2.Error as e:
        logger.error(f"Error saving statuses to history for {manager}: {e}")
        conn.rollback()
        raise

def get_statuses_from_history(conn, report_date: date, manager: str) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å—ã STL –∏ NAK –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é –¥–∞—Ç—É."""
    query = f"SELECT status, count FROM {HISTORY_TABLE_NAME} WHERE report_date = %s AND manager = %s AND status IN ('STL', 'NAK');"
    params = (report_date, manager)
    results = _execute_query(conn, query, params, f"STL/NAK history for {manager} on {report_date}")
    statuses = {'STL': 0, 'NAK': 0}
    for status, count in results:
        if status in statuses:
            statuses[status] = count
    return statuses


def get_current_statuses_and_inflow(conn, manager: str, today: date) -> (dict, dict, dict):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç—Ä–∏ —Å–ª–æ–≤–∞—Ä—è:
    1. –ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Å—Ç–∞—Ç—É—Å–µ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è.
    2. –î–Ω–µ–≤–Ω–æ–π –ø—Ä–∏—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤ (–¥–ª—è —Å—Ç–∞—Ç—É—Å–æ–≤ —Å –¥–∞—Ç–æ–π –≤—Ö–æ–¥–∞).
    3. –î–Ω–µ–≤–Ω–æ–π –æ—Ç—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤ (–¥–ª—è —Å—Ç–∞—Ç—É—Å–æ–≤ —Å –¥–∞—Ç–æ–π –≤—ã—Ö–æ–¥–∞).
    """
    # 1. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ê–ë–°–û–õ–Æ–¢–ù–´–ï –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å–µ–≥–æ–¥–Ω—è (–í–û–ó–í–†–ê–©–ê–ï–ú –°–¢–ê–†–£–Æ –õ–û–ì–ò–ö–£)
    query = "SELECT status_wspolpracy, data_ostatniego_zamowienia FROM planfix_clients WHERE menedzer = %s AND is_deleted = false AND status_wspolpracy IS NOT NULL AND status_wspolpracy != ''"
    params = (manager,)
    results = _execute_query(conn, query, params, f"current statuses for {manager}")

    current_totals = {status: 0 for status in CLIENT_STATUSES}
    for full_status, last_order_date in results:
        status_clean = full_status.strip()
        if status_clean == 'Stali klienci':
            days_diff = float('inf')
            if last_order_date and last_order_date.strip():
                try:
                    days_diff = (today - datetime.strptime(last_order_date.strip()[:10], '%d-%m-%Y').date()).days
                except (ValueError, TypeError):
                    pass
            short_status = 'STL' if days_diff <= 30 else 'NAK'
        else:
            short_status = STATUS_MAPPING.get(status_clean)

        if short_status and short_status in current_totals:
            current_totals[short_status] += 1
            
    # 2. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –î–ù–ï–í–ù–û–ô –ü–†–ò–¢–û–ö
    daily_inflow = {status: 0 for status in CLIENT_STATUSES}
    for status, col_name in STATUS_INFLOW_DATE_COLS.items():
        query = f"SELECT COUNT(*) FROM planfix_clients WHERE menedzer = %s AND {col_name} IS NOT NULL AND {col_name} != '' AND TO_DATE({col_name}, 'DD-MM-YYYY') = %s AND is_deleted = false"
        params_inflow = (manager, today)
        (count,) = _execute_query(conn, query, params_inflow, f"inflow for {status}")[0]
        daily_inflow[status] = count

    # 3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –î–ù–ï–í–ù–û–ô –û–¢–¢–û–ö –ø–æ –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–µ
    daily_outflow = {status: 0 for status in CLIENT_STATUSES}
    yesterday = today - timedelta(days=1)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–Ω–∏–º–∫–∏ –≤—á–µ—Ä–∞—à–Ω–µ–≥–æ –∏ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è
    yesterday_statuses = get_current_statuses_for_date(conn, manager, yesterday)
    today_statuses = get_current_statuses_for_date(conn, manager, today)
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç—Ç–æ–∫ –∫–∞–∫ —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –≤—á–µ—Ä–∞—à–Ω–∏–º –∏ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
    for status in CLIENT_STATUSES:
        yesterday_count = yesterday_statuses.get(status, 0)
        today_count = today_statuses.get(status, 0)
        
        # –û—Ç—Ç–æ–∫ = –±—ã–ª–æ –≤—á–µ—Ä–∞ –±–æ–ª—å—à–µ, —á–µ–º —Å–µ–≥–æ–¥–Ω—è
        if yesterday_count > today_count:
            daily_outflow[status] = yesterday_count - today_count

    return current_totals, daily_inflow, daily_outflow

def get_current_statuses_for_date(conn, manager: str, target_date: date) -> dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é –¥–∞—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –¥–ª—è CURRENT)"""
    
    # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ CURRENT –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É - –±–µ—Ä–µ–º status_wspolpracy –∏–∑ Planfix
    # –≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ CURRENT –¥–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    query = "SELECT status_wspolpracy, data_ostatniego_zamowienia FROM planfix_clients WHERE menedzer = %s AND is_deleted = false AND status_wspolpracy IS NOT NULL AND status_wspolpracy != ''"
    params = (manager,)
    results = _execute_query(conn, query, params, f"statuses for {manager} on {target_date}")

    current_totals = {status: 0 for status in CLIENT_STATUSES}
    for full_status, last_order_date in results:
        status_clean = full_status.strip()
        if status_clean == 'Stali klienci':
            days_diff = float('inf')
            if last_order_date and last_order_date.strip():
                try:
                    days_diff = (target_date - datetime.strptime(last_order_date.strip()[:10], '%d-%m-%Y').date()).days
                except (ValueError, TypeError):
                    pass
            short_status = 'STL' if days_diff <= 30 else 'NAK'
        else:
            short_status = STATUS_MAPPING.get(status_clean)

        if short_status and short_status in current_totals:
            current_totals[short_status] += 1
    
    return current_totals


def get_global_max_count(all_managers_data: dict) -> int:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π –º–∞–∫—Å–∏–º—É–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è {manager: {status: count}}."""
    global_max = 0
    if all_managers_data:
        for data in all_managers_data.values():
            if data and data.values():
                 max_val = max(data.values())
                 if max_val > global_max:
                    global_max = max_val
    return global_max if global_max > 0 else 1 # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å

def calculate_rzm_totals(status_changes):
    """–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ RZM"""
    
    # CURRENT = —Å—É–º–º–∞ –≤—Å–µ—Ö —Ç–µ–∫—É—â–∏—Ö —Å—Ç–∞—Ç—É—Å–æ–≤
    total_current = sum(data['current'] for data in status_changes.values())
    
    # NET = —Å—É–º–º–∞ –≤—Å–µ—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π
    total_net = sum(data['net'] for data in status_changes.values())
    
    return total_current, total_net

def validate_data_on_the_fly(conn, manager, today):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ª–µ—Ç—É –±–µ–∑ –Ω–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü"""
    
    issues = []
    
    try:
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞—Ç
        invalid_dates_check = """
        SELECT id, status_wspolpracy,
               data_dodania_do_nowi, data_dodania_do_w_trakcie,
               data_dodania_do_perspektywiczni, data_dodania_do_rezygnacja,
               data_dodania_do_brak_kontaktu, data_dodania_do_archiwum,
               data_pierwszego_zamowienia, data_ostatniego_zamowienia
        FROM planfix_clients 
        WHERE menedzer = %s AND is_deleted = false
          AND (
            (data_dodania_do_nowi IS NOT NULL AND data_dodania_do_nowi != '' 
             AND TO_DATE(data_dodania_do_nowi, 'DD-MM-YYYY') IS NULL)
            OR
            (data_dodania_do_w_trakcie IS NOT NULL AND data_dodania_do_w_trakcie != '' 
             AND TO_DATE(data_dodania_do_w_trakcie, 'DD-MM-YYYY') IS NULL)
            OR
            (data_dodania_do_perspektywiczni IS NOT NULL AND data_dodania_do_perspektywiczni != '' 
             AND TO_DATE(data_dodania_do_perspektywiczni, 'DD-MM-YYYY') IS NULL)
            OR
            (data_dodania_do_rezygnacja IS NOT NULL AND data_dodania_do_rezygnacja != '' 
             AND TO_DATE(data_dodania_do_rezygnacja, 'DD-MM-YYYY') IS NULL)
            OR
            (data_dodania_do_brak_kontaktu IS NOT NULL AND data_dodania_do_brak_kontaktu != '' 
             AND TO_DATE(data_dodania_do_brak_kontaktu, 'DD-MM-YYYY') IS NULL)
            OR
            (data_dodania_do_archiwum IS NOT NULL AND data_dodania_do_archiwum != '' 
             AND TO_DATE(data_dodania_do_archiwum, 'DD-MM-YYYY') IS NULL)
            OR
            (data_pierwszego_zamowienia IS NOT NULL AND data_pierwszego_zamowienia != '' 
             AND TO_DATE(data_pierwszego_zamowienia, 'DD-MM-YYYY') IS NULL)
            OR
            (data_ostatniego_zamowienia IS NOT NULL AND data_ostatniego_zamowienia != '' 
             AND TO_DATE(data_ostatniego_zamowienia, 'DD-MM-YYYY') IS NULL)
          )
        """
        
        results = _execute_query(conn, invalid_dates_check, (manager,), "validation: invalid_dates")
        if results:
            issues.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã: {len(results)} –∑–∞–ø–∏—Å–µ–π")
            logger.warning(f"Data validation issues for {manager} - invalid_dates: {len(results)}")
    
    except Exception as e:
        logger.error(f"Validation check failed: {e}")
        issues.append(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}")
    
    return issues

def format_client_status_report(changes: dict, global_max: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å IN/OUT."""
    total_sum = sum(data['current'] for data in changes.values())
    if total_sum == 0: total_sum = 1

    # –î–ª–∏–Ω–∞ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏
    separator_length = 33  # "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
    change_strings = {}
    inout_strings = {}
    percent_strings = {}
    
    for status in CLIENT_STATUSES:
        data = changes[status]
        current = data['current']
        change = data['net']
        inflow = data['inflow']
        outflow = data['outflow']
        
        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ
        change_str = f"+{change}" if change > 0 else (str(change) if change < 0 else "")
        change_strings[status] = change_str
        
        # IN/OUT
        inout_str = f"[+{inflow}/-{outflow}]"
        inout_strings[status] = inout_str
        
        # –ü—Ä–æ—Ü–µ–Ω—Ç—ã –ë–ï–ó —Å–∫–æ–±–æ–∫
        percentage = math_round(float(current) / float(total_sum) * 100)
        percent_str = f"{percentage}%"
        percent_strings[status] = percent_str

    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ
    max_current_len = 3   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (3 —Ü–∏—Ñ—Ä—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
    max_change_len = 3    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏–π (-99)
    max_inout_len = 9     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è [IN/OUT] ([+99/-99])
    max_percent_len = 3   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ (100%)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –¥–ª–∏–Ω—ã
    for status in CLIENT_STATUSES:
        data = changes[status]
        current = data['current']
        change_str = change_strings[status]
        inout_str = inout_strings[status]
        percent_str = percent_strings[status]
        
        max_current_len = max(max_current_len, len(str(current)))
        max_change_len = max(max_change_len, len(change_str))
        max_inout_len = max(max_inout_len, len(inout_str))
        max_percent_len = max(max_percent_len, len(percent_str))

    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞ –±–∞—Ä–∞ –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏
    max_bar_len = 5  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª–∏–Ω–∞ –±–∞—Ä–∞ –¥–ª—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (—É–º–µ–Ω—å—à–µ–Ω–æ –Ω–∞ 2)
    
    lines = []
    
    for status in CLIENT_STATUSES:
        data = changes[status]
        current = data['current']
        indicator = data['direction']
        change_str = change_strings[status]
        inout_str = inout_strings[status]
        percent_str = percent_strings[status]

        # –ë–∞—Ä
        bar_len = max(1, math_round(float(current) / float(global_max) * max_bar_len)) if global_max > 0 and current > 0 else 0
        bar_str = '‚ñà' * bar_len

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ
        line = (
            f"{status} {bar_str:<5} "
            f"{current:>{max_current_len}} "
            f"{change_str:>{max_change_len}} {indicator} "
            f"{inout_str:>{max_inout_len}} "
            f"{percent_str:>{max_percent_len}}"
        )
        
        lines.append(line)

    return "\n".join(lines)

def send_to_telegram(message: str):
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram."""
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        payload = {'chat_id': CHAT_ID, 'text': message, 'parse_mode': 'Markdown'}
        response = requests.post(url, json=payload, timeout=10)
        if response.status_code == 200:
            logger.info("Message sent successfully to Telegram")
        else:
            logger.error(f"Failed to send message to Telegram: {response.text}")
    except Exception as e:
        logger.error(f"Error sending to Telegram: {str(e)}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á—ë—Ç–∞."""
    today = date.today()
    logger.info(f"Starting client status report generation for date: {today}")

    conn = None
    try:
        conn = psycopg2.connect(host=PG_HOST, dbname=PG_DB, user=PG_USER, password=PG_PASSWORD, port=PG_PORT)
        create_history_table_if_not_exists(conn)

        all_managers_totals = {}
        all_managers_inflow = {}
        all_managers_outflow = {}
        all_validation_issues = {}
        
        for manager in (m['planfix_user_name'] for m in MANAGERS_KPI if m['planfix_user_name']):
            # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            validation_issues = validate_data_on_the_fly(conn, manager, today)
            all_validation_issues[manager] = validation_issues
            
            # 2. –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—É—Å—ã –∏ –ø–æ—Ç–æ–∫–∏
            totals, inflow, outflow = get_current_statuses_and_inflow(conn, manager, today)
            all_managers_totals[manager] = totals
            all_managers_inflow[manager] = inflow
            all_managers_outflow[manager] = outflow
            save_statuses_to_history(conn, today, manager, totals)

        global_max = get_global_max_count(all_managers_totals)
        logger.info(f"Global max count for today is: {global_max}")

        yesterday = today - timedelta(days=1)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∏—Ä–∏–Ω—ã –¥–ª—è –≤—Å–µ—Ö –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
        global_max_current_len = 6   # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        global_max_change_len = 4    # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
        
        all_reports = []
        for manager, current_totals in all_managers_totals.items():
            report_body = ""
            try:
                logger.info(f"Processing report for manager: {manager}")
                
                previous_stl_nak = get_statuses_from_history(conn, yesterday, manager)
                
                status_changes = {}
                for status in CLIENT_STATUSES:
                    curr_count = current_totals.get(status, 0)
                    inflow = all_managers_inflow[manager].get(status, 0)
                    outflow = all_managers_outflow[manager].get(status, 0)
                    
                    # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞: NET = INFLOW - OUTFLOW –¥–ª—è –≤—Å–µ—Ö —Å—Ç–∞—Ç—É—Å–æ–≤
                    diff = inflow - outflow

                    direction = "‚ñ≤" if diff > 0 else ("‚ñº" if diff < 0 else "-")
                    status_changes[status] = {
                        'current': curr_count, 
                        'net': diff, 
                        'direction': direction,
                        'inflow': inflow,
                        'outflow': outflow
                    }
                
                logger.info(f"Got status changes for {manager}: {status_changes}")
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–ª–æ –æ—Ç—á–µ—Ç–∞ (—Å—Ç—Ä–æ–∫–∏ —Å KPI)
                report_kpi_lines = format_client_status_report(status_changes, global_max)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–µ–ø–µ—Ä—å –±—É–¥–µ—Ç –æ–±—â–∏–π, –∞ –∑–¥–µ—Å—å —Ç–æ–ª—å–∫–æ –∏–º—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞
                manager_header = f"üë§ {manager}:"
                separator = "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏—Ç–æ–≥–æ–≤
                total_current, total_net = calculate_rzm_totals(status_changes)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç—Ä–æ–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º
                total_current_str = str(total_current)
                total_change_str = f"+{total_net}" if total_net > 0 else (str(total_net) if total_net < 0 else "")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ –¥–ª–∏–Ω—ã —á—Ç–æ –∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ—Ç—á–µ—Ç–µ
                max_current_len = max(3, len(total_current_str))
                max_change_len = max(3, len(total_change_str))
                
                # –§–æ—Ä–º–∞—Ç –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏: "RZM BAR CURRENT CHANGE IND"
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç —á—Ç–æ –∏ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ç—Ä–æ–∫–∞—Ö, –Ω–æ –±–µ–∑ INOUT –∏ PERCENT
                # RZM (3) + " " (1) + BAR (5) + " " (1) + CURRENT + " " (1) + CHANGE + " " (1) + IND (1)
                footer = (
                    f"RZM {'':<5} "
                    f"{total_current_str:>{max_current_len}} "
                    f"{total_change_str:>{max_change_len}} "
                )

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã
                validation_info = ""
                validation_issues = all_validation_issues.get(manager, [])
                if validation_issues:
                    validation_info = "\n\n‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏:\n"
                    for issue in validation_issues:
                        validation_info += f"‚Ä¢ {issue}\n"

                full_report_for_manager = f"{manager_header}\n{separator}\n{report_kpi_lines}\n{separator}\n{footer}{validation_info}"
                all_reports.append(full_report_for_manager)
                
                logger.info(f"Generated report for {manager}:\n{full_report_for_manager}")

            except Exception as e:
                logger.error(f"Failed to generate report for {manager}: {e}", exc_info=True)
                error_message = f"Error generating report for {manager}: {e}"
                all_reports.append(error_message)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–∏–Ω –æ–±—â–∏–π –æ—Ç—á–µ—Ç
        if all_reports:
            final_report_header = f"WORONKA_{today.strftime('%d.%m.%Y')}"
            final_report = f"```{final_report_header}\n\n" + "\n\n".join(all_reports) + "\n```"
            send_to_telegram(final_report)

    except psycopg2.Error as e:
        logger.error(f"Database connection error: {e}", exc_info=True)
        send_to_telegram(f"Database connection error: {e}")
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}", exc_info=True)
        send_to_telegram(f"An unexpected error occurred: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == '__main__':
    main()